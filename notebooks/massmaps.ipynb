{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b559f4cb-a670-42f7-a25e-8317d995fbef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment line below to install exlib\n",
    "# !pip install exlib\n",
    "import sys; sys.path.insert(0, \"../../exlib/src\")\n",
    "import exlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a19afcc9-b4e1-4a52-a254-347fb8d92893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/runai-home/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 98.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from exlib.datasets.mass_maps import MassMapsDataset\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "561fb4e7-b30a-4f1a-b680-e3fce0fa9464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd63df2bee6747f09adbbc1aa56dbb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fd72296cee4056b8a64a17759f59e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedefde564914db5a88b5946cd821646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/405M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3300063c6949dcb7ea107b05281383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/180M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d99748c502a449e847b592e01061084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/180M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea50a42c20004b53a8ea57ac58edacf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b151d9327904e3b92d625b6a1906414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/90000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11f46054110493aaa991361b3601575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addf5f6cc53143c2a1902fab15451a93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d36de89ffa43eeb1d87edd720529af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/153 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "val_dataset = MassMapsDataset(split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa3cf985-410a-49ae-9194-d1acd917d4e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = val_dataset[0:2]['input'], val_dataset[0:2]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0164ef94-28a7-419e-a9e9-b1a5ae6a87a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:  ········\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from getpass import getpass\n",
    "\n",
    "openai.api_key = getpass('Enter your OpenAI API key: ')\n",
    "\n",
    "client = openai.OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94ae5455-b446-4ed3-bbc5-1cca1e3dcadc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "\n",
    "def massmap_to_pil(tensor):\n",
    "    \"\"\"\n",
    "    Converts a PyTorch tensor to a PIL image.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): A tensor representing the map with shape (1, H, W)\n",
    "\n",
    "    Returns:\n",
    "    PIL.Image: An image object.\n",
    "    \"\"\"\n",
    "    # Check if the tensor is in the range 0-1, if yes, scale to 0-255\n",
    "    plt.imshow(tensor[0])\n",
    "    plt.axis('off')  # remove axes if desired\n",
    "\n",
    "    # Save the displayed image to a buffer\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "    # Reset buffer position\n",
    "    buf.seek(0)\n",
    "\n",
    "    # Load the image with PIL\n",
    "    pil_image = PIL.Image.open(buf)\n",
    "    return pil_image\n",
    "\n",
    "def convert_pil_to_base64(pil_image):\n",
    "    \"\"\"\n",
    "    Converts a PIL image to a base64-encoded string.\n",
    "    \"\"\"\n",
    "    if pil_image.mode == \"RGBA\":\n",
    "        pil_image = pil_image.convert(\"RGB\")\n",
    "\n",
    "    buffered = io.BytesIO()\n",
    "    pil_image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "di = 0\n",
    "image = X[di]\n",
    "image_pil = massmap_to_pil(image)\n",
    "image_base64 = convert_pil_to_base64(image_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd1a3138-f00a-4aac-b247-81df380533b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_messages(prompt, images=None, system_prompt=None):\n",
    "    system_message = [\n",
    "                {'role': 'system', 'content': [{'type': 'text', 'text': system_prompt}]},\n",
    "            ]\n",
    "\n",
    "    image_payload = []\n",
    "    if images:\n",
    "        image_payload = [\n",
    "            {\n",
    "                \"type\": 'image_url',\n",
    "                'image_url': {'url': f\"data:image/jpeg;base64,{convert_pil_to_base64(image)}\"}\n",
    "            }\n",
    "            for image in images\n",
    "        ]\n",
    "\n",
    "    new_message = [\n",
    "        {'role': 'user', 'content': image_payload + [\n",
    "            {'type': 'text', 'text': prompt}\n",
    "        ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    messages = system_message + new_message\n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d905589-471a-43a0-be7d-b84c4eda1e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def text2json(text):\n",
    "    match = re.search(r'```json(.*?)```', text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(1).strip()\n",
    "        # Escape single backslashes\n",
    "        json_str = json_str.replace('\\\\', '\\\\\\\\')\n",
    "        data = json.loads(json_str)\n",
    "    else:\n",
    "        data = None\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40ce577a-a797-4552-af54-9726a73bc7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"This is an image of a weak lensing map. Please predict Omega_m and sigma_8 values from this and provide a reasoning chain for what interpretable cosmological features you see from this map that you use to make such predictions. Provide a short paragraph that is around 100-200 words.\"\"\"\n",
    "\n",
    "system_prompt = \"You are an expert cosmologist.\"\n",
    "images = [image_pil]\n",
    "messages = get_messages(prompt, images, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a6343aa-6b57-4e15-a6ec-d5ec1338edb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting diskcache\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: diskcache\n",
      "Successfully installed diskcache-5.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install diskcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86bb35b7-d6ab-46b1-bf65-f2e2c3f0c123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diskcache import Cache\n",
    "cache = Cache(\"/shared_data0/llm_cachedir\")\n",
    "\n",
    "@cache.memoize()\n",
    "def get_llm_output(prompt, images=None, system_prompt=''):\n",
    "    \"\"\"\n",
    "    prompt: str\n",
    "    images: list of PIL images\n",
    "    system_prompt: str\n",
    "    \"\"\"\n",
    "    messages = get_messages(prompt, images, system_prompt)\n",
    "    response = client.chat.completions.create(\n",
    "            model='gpt-4o-mini',\n",
    "            messages=messages,\n",
    "            response_format={'type': 'text'},\n",
    "            temperature=0,\n",
    "            max_tokens=500,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac82aab5-52f5-4f57-b859-e5e4b838b294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from diskcache import Cache\n",
    "from typing import Tuple\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "cache = Cache(\"/shared_data0/llm_cachedir\")\n",
    "\n",
    "@cache.memoize()\n",
    "def get_llm_score(prompt, images=None, system_prompt=None) -> Tuple[str, float]:\n",
    "    if system_prompt is None:\n",
    "        system_prompt = \"Answer only as a YES or NO.\"\n",
    "    messages = get_messages(prompt, images, system_prompt)\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        response_format={\"type\": \"text\"},\n",
    "        temperature=0,\n",
    "        max_tokens=1,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        logit_bias={31958: 100, 14695: 100},\n",
    "        logprobs=True,\n",
    "    )\n",
    "    completion = response.choices[0].logprobs.content[0].token.strip().lower()\n",
    "    logprob = response.choices[0].logprobs.content[0].logprob\n",
    "    sleep_duration = random.uniform(0.5, 2)\n",
    "    time.sleep(sleep_duration)\n",
    "    return completion, math.exp(logprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "829e9769-fe78-411d-b266-87ecf1ad672a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Image: pass\n",
    "\n",
    "class Timeseries: pass\n",
    "\n",
    "class AlignmentScores: pass\n",
    "\n",
    "\n",
    "def get_llm_generated_answer(\n",
    "    example: str | torch.Tensor, #Image | Timeseries,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        example (str | Image | timeseries): The input example from which we want an LLM to generate some answer to a task,\n",
    "          e.g., the emotion classification task.\n",
    "    \"\"\"\n",
    "    prompt = \"\"\"This is an image of a weak lensing map. Please predict Omega_m and sigma_8 values from this and provide a reasoning chain for what interpretable cosmological features you see from this map that you use to make such predictions. Provide a short paragraph that is around 100-200 words.\"\"\"\n",
    "    system_prompt = \"You are an expert cosmologist.\"\n",
    "    \n",
    "    image_pil = massmap_to_pil(example)\n",
    "    return get_llm_output(prompt, [image_pil], system_prompt)\n",
    "\n",
    "\n",
    "def isolate_individual_features(\n",
    "    explanation: str\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        explanation (str): The LLM-generated reasoning chain of why it gave a specific answer to an example.\n",
    "        \n",
    "    Returns:\n",
    "        raw_atomic_claims (list[str]): A list of strings where each string is an isolated claim (includes relevant and irrelevant claims).\n",
    "    \"\"\"\n",
    "    system_prompt_text2claims = \"\"\"You are an expert cosmologist. This is the explanation and answer for predicting from mass maps. Please break it down into atomic claims.\n",
    "Output format:\n",
    "Claims:\n",
    "```json\n",
    "[\n",
    "    \"<claim 1>\",\n",
    "    \"<claim 2>\",\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    raw_atomic_claims = get_llm_output(explanation, system_prompt=system_prompt_text2claims)\n",
    "    # return raw_atomic_claims\n",
    "    return text2json(raw_atomic_claims)\n",
    "\n",
    "\n",
    "def is_claim_relevant(\n",
    "    example: str | torch.Tensor,\n",
    "    answer: str,\n",
    "    atomic_claim: str,\n",
    "    threshold: float = 0.9\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    For a claim to be relevant, it must be:\n",
    "        (1) Supported by the example.\n",
    "        (2) Answers the question of why the LLM gave the answer it did for this specific example.\n",
    "\n",
    "    Args:\n",
    "        example (str | Image | timeseries): The input example from a dataset from which to distill the relevant features from.\n",
    "        answer (str): The LLM-generated answer to the example.\n",
    "        atomic_claim (str): A claim to check if it is relevant to the example.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt_is_claim_relevant = \"\"\"You are an expert cosmologist. You need to check if a claim is relevant to the image of weak lensing map or not.\n",
    "For a claim to be relevant, it must be:\n",
    "(1) Supported by the example.\n",
    "(2) Answers the question of why the LLM gave the answer it did for this specific example.\n",
    "\n",
    "Please only answer YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "    prompt_is_claim_relevant = \"\"\"Answer:\n",
    "{}\n",
    "\n",
    "Atomic Claim:\n",
    "{}\n",
    "\"\"\".format(answer, atomic_claim)\n",
    "\n",
    "    image_pil = massmap_to_pil(example)\n",
    "    completion, prob = get_llm_score(prompt_is_claim_relevant, \n",
    "              images=[image_pil], \n",
    "              system_prompt=system_prompt_is_claim_relevant)\n",
    "\n",
    "    return completion == \"yes\" and prob >= threshold\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "\n",
    "def distill_relevant_features(\n",
    "    example: str | torch.Tensor,\n",
    "    answer: str,\n",
    "    atomic_claims: list[str],\n",
    "    threshold: float = 0.9\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        example (str | Image | timeseries): The input example from a dataset from which to distill the relevant features from.\n",
    "        answer (str): The LLM-generated answer to the example.\n",
    "        raw_atomic_claims (list[str]): A list of strings where each string is an isolated claim (includes relevant and irrelevant claims).\n",
    "    Returns:\n",
    "        atomic_claims (list[str]): A list of strings where each string is a relevant claim.\n",
    "    \"\"\"\n",
    "    atomic_claims = []\n",
    "    for raw_atomic_claim in raw_atomic_claims:\n",
    "        if is_claim_relevant(example, llm_generated_answer, raw_atomic_claim):\n",
    "            atomic_claims.append(raw_atomic_claim)\n",
    "    return atomic_claims\n",
    "\n",
    "def calculate_expert_alignment_score(\n",
    "    atomic_claims: list[str],\n",
    ") -> AlignmentScores:\n",
    "    \"\"\"\n",
    "    Computes the individual (and overall) alignment score of all the relevant atomic claims.\n",
    "\n",
    "    Possibly needs a domain-independent aggregation function.\n",
    "    Args:\n",
    "        atomic_claims (list[str]): A list of strings where each string is a relevant claim.\n",
    "    Returns:\n",
    "        1. Alignment score of each individual atomic claims.\n",
    "        2. Overall alignment score of all the atomic claims.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"You are an expert cosmologist. You need to check if each claim is aligned with domain knowledge of cosmology. Computes the individual (and overall) alignment score of all the atomic claims.\n",
    "\n",
    "Input format:\n",
    "Claims:\n",
    "```json\n",
    "[\n",
    "    \"<claim 1>\",\n",
    "    \"<claim 2>\",\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Output format:\n",
    "Scores:\n",
    "```json\n",
    "{\n",
    "    \"alignment_scores\": {\n",
    "        {\"claim\": \"<claim 1>\", \"score\": <alignment score ranging from 1 to 5>},\n",
    "        {\"claim\": \"<claim 2>\", \"score\": <alignment score ranging from 1 to 5>},\n",
    "        ...\n",
    "    },\n",
    "    \"total_score\": <total alignment score ranging from 1 to 5>\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "    prompt = \"\"\"Claims:\n",
    "```json\n",
    "{}\n",
    "```\n",
    "\"\"\".format(json.dumps(atomic_claims))\n",
    "          \n",
    "    alignment_scores = get_llm_output(prompt, system_prompt=system_prompt)\n",
    "    return text2json(alignment_scores)\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0f11a866-4e9b-4940-bf5e-92b9419af9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "di = 0\n",
    "image = X[di]\n",
    "image_pil = massmap_to_pil(image)\n",
    "image_base64 = convert_pil_to_base64(image_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f04fbc94-2ab0-4c0c-94c9-6ca386f30472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_generated_answer = get_llm_generated_answer(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6df85601-120c-4ec2-9d6f-6906dd73768d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a weak lensing map, the distribution of dark matter can be inferred from the distortion of background galaxies due to gravitational lensing. The presence of structures, such as clusters and filaments, indicates the underlying matter distribution. \\n\\nFrom this map, we can estimate the values of \\\\(\\\\Omega_m\\\\) (the matter density parameter) and \\\\(\\\\sigma_8\\\\) (the amplitude of density fluctuations). A higher density of dark matter structures suggests a larger \\\\(\\\\Omega_m\\\\), while the degree of clustering informs us about \\\\(\\\\sigma_8\\\\). \\n\\nIf the map shows significant clustering and pronounced features, we might predict \\\\(\\\\Omega_m\\\\) to be around 0.3 to 0.4, indicating a substantial amount of matter in the universe. For \\\\(\\\\sigma_8\\\\), if the structures appear tightly clustered, values around 0.8 to 0.9 could be inferred, reflecting a high amplitude of fluctuations. Conversely, a more diffuse distribution would suggest lower values. Thus, analyzing the density and distribution of features in the map allows us to make these cosmological predictions.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_generated_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f87f22d1-1c77-4df9-9acf-e8949de9a08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_atomic_claims = isolate_individual_features(llm_generated_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3fd441dd-1cdc-48c4-bfa8-b0c15ca9ce81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a weak lensing map, the distribution of dark matter can be inferred from the distortion of background galaxies due to gravitational lensing.',\n",
       " 'The presence of structures, such as clusters and filaments, indicates the underlying matter distribution.',\n",
       " 'From the weak lensing map, we can estimate the values of \\\\(\\\\Omega_m\\\\) (the matter density parameter) and \\\\(\\\\sigma_8\\\\) (the amplitude of density fluctuations).',\n",
       " 'A higher density of dark matter structures suggests a larger \\\\(\\\\Omega_m\\\\).',\n",
       " 'The degree of clustering in the weak lensing map informs us about \\\\(\\\\sigma_8\\\\).',\n",
       " 'If the map shows significant clustering and pronounced features, we might predict \\\\(\\\\Omega_m\\\\) to be around 0.3 to 0.4.',\n",
       " 'A prediction of \\\\(\\\\Omega_m\\\\) around 0.3 to 0.4 indicates a substantial amount of matter in the universe.',\n",
       " 'If the structures in the map appear tightly clustered, values of \\\\(\\\\sigma_8\\\\) around 0.8 to 0.9 could be inferred.',\n",
       " 'A high amplitude of fluctuations is reflected by values of \\\\(\\\\sigma_8\\\\) around 0.8 to 0.9.',\n",
       " 'A more diffuse distribution of structures in the map would suggest lower values of \\\\(\\\\sigma_8\\\\).',\n",
       " 'Analyzing the density and distribution of features in the weak lensing map allows us to make cosmological predictions.']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_atomic_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0d53efe9-0b76-4c01-a5ca-85774b65bf2a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, False, False, False, False, True, True]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim_relevances = [is_claim_relevant(image, llm_generated_answer, raw_atomic_claim) \\\n",
    "    for raw_atomic_claim in raw_atomic_claims]\n",
    "claim_relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "02e9dbfa-287d-487c-af47-3101f7f47b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In a weak lensing map, the distribution of dark matter can be inferred from the distortion of background galaxies due to gravitational lensing.',\n",
       " 'The presence of structures, such as clusters and filaments, indicates the underlying matter distribution.',\n",
       " 'From the weak lensing map, we can estimate the values of \\\\(\\\\Omega_m\\\\) (the matter density parameter) and \\\\(\\\\sigma_8\\\\) (the amplitude of density fluctuations).',\n",
       " 'A higher density of dark matter structures suggests a larger \\\\(\\\\Omega_m\\\\).',\n",
       " 'The degree of clustering in the weak lensing map informs us about \\\\(\\\\sigma_8\\\\).',\n",
       " 'A more diffuse distribution of structures in the map would suggest lower values of \\\\(\\\\sigma_8\\\\).',\n",
       " 'Analyzing the density and distribution of features in the weak lensing map allows us to make cosmological predictions.']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atomic_claims = distill_relevant_features(image, llm_generated_answer, raw_atomic_claims)\n",
    "atomic_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "aa3074b5-32b5-46b0-bd37-e04faee3f04a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alignment_scores': [{'claim': 'In a weak lensing map, the distribution of dark matter can be inferred from the distortion of background galaxies due to gravitational lensing.',\n",
       "   'score': 5},\n",
       "  {'claim': 'The presence of structures, such as clusters and filaments, indicates the underlying matter distribution.',\n",
       "   'score': 5},\n",
       "  {'claim': 'From the weak lensing map, we can estimate the values of \\\\\\\\(\\\\\\\\Omega_m\\\\\\\\) (the matter density parameter) and \\\\\\\\(\\\\\\\\sigma_8\\\\\\\\) (the amplitude of density fluctuations).',\n",
       "   'score': 5},\n",
       "  {'claim': 'A higher density of dark matter structures suggests a larger \\\\\\\\(\\\\\\\\Omega_m\\\\\\\\).',\n",
       "   'score': 5},\n",
       "  {'claim': 'The degree of clustering in the weak lensing map informs us about \\\\\\\\(\\\\\\\\sigma_8\\\\\\\\).',\n",
       "   'score': 5},\n",
       "  {'claim': 'A more diffuse distribution of structures in the map would suggest lower values of \\\\\\\\(\\\\\\\\sigma_8\\\\\\\\).',\n",
       "   'score': 5},\n",
       "  {'claim': 'Analyzing the density and distribution of features in the weak lensing map allows us to make cosmological predictions.',\n",
       "   'score': 5}],\n",
       " 'total_score': 5}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_scores = calculate_expert_alignment_score(atomic_claims)\n",
    "alignment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fcffb5ca-8977-403d-999a-df4cf8beedf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def calculate_expert_alignment_score(\n",
    "#     atomic_claims: list[str],\n",
    "# ) -> AlignmentScores:\n",
    "#     \"\"\"\n",
    "#     Computes the individual (and overall) alignment score of all the relevant atomic claims.\n",
    "\n",
    "#     Possibly needs a domain-independent aggregation function.\n",
    "#     Args:\n",
    "#         atomic_claims (list[str]): A list of strings where each string is a relevant claim.\n",
    "#     Returns:\n",
    "#         1. Alignment score of each individual atomic claims.\n",
    "#         2. Overall alignment score of all the atomic claims.\n",
    "#     \"\"\"\n",
    "#     raise NotImplementedError()\n",
    "\n",
    "# answer = llm_generated_answer\n",
    "# atomic_claim = raw_atomic_claims[0]\n",
    "\n",
    "system_prompt = \"\"\"You are an expert cosmologist. You need to check if each claim is aligned with domain knowledge of cosmology. Computes the individual (and overall) alignment score of all the atomic claims.\n",
    "\n",
    "Input format:\n",
    "Claims:\n",
    "```json\n",
    "[\n",
    "    \"<claim 1>\",\n",
    "    \"<claim 2>\",\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "Output format:\n",
    "Scores:\n",
    "```json\n",
    "{\n",
    "    \"alignment_scores\": {\n",
    "        {\"claim\": \"<claim 1>\", \"score\": <alignment score ranging from 1 to 5>},\n",
    "        {\"claim\": \"<claim 2>\", \"score\": <alignment score ranging from 1 to 5>},\n",
    "        ...\n",
    "    },\n",
    "    \"total_score\": <total alignment score ranging from 1 to 5>\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"Claims:\n",
    "```json\n",
    "{}\n",
    "```\n",
    "\"\"\".format(json.dumps(atomic_claims))\n",
    "          \n",
    "alignment_scores = get_llm_output(prompt, [image_pil], system_prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0abb81a4-5fdf-43c4-bf09-815e09770649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Scores:\\n```json\\n{\\n    \"alignment_scores\": [\\n        {\"claim\": \"In a weak lensing map, the distribution of dark matter can be inferred from the distortion of background galaxies due to gravitational lensing.\", \"score\": 5},\\n        {\"claim\": \"The presence of structures, such as clusters and filaments, indicates the underlying matter distribution.\", \"score\": 5},\\n        {\"claim\": \"From the weak lensing map, we can estimate the values of \\\\\\\\(\\\\\\\\Omega_m\\\\\\\\) (the matter density parameter) and \\\\\\\\(\\\\\\\\sigma_8\\\\\\\\) (the amplitude of density fluctuations).\", \"score\": 5},\\n        {\"claim\": \"A higher density of dark matter structures suggests a larger \\\\\\\\(\\\\\\\\Omega_m\\\\\\\\).\", \"score\": 5},\\n        {\"claim\": \"The degree of clustering in the weak lensing map informs us about \\\\\\\\(\\\\\\\\sigma_8\\\\\\\\).\", \"score\": 5},\\n        {\"claim\": \"A more diffuse distribution of structures in the map would suggest lower values of \\\\\\\\(\\\\\\\\sigma_8\\\\\\\\).\", \"score\": 5},\\n        {\"claim\": \"Analyzing the density and distribution of features in the weak lensing map allows us to make cosmological predictions.\", \"score\": 5}\\n    ],\\n    \"total_score\": 5\\n}\\n```'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047833ac-d9ad-48ba-9ab8-fa55b978e9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_claim_relevant(\n",
    "#     example: str | torch.Tensor,\n",
    "#     answer: str,\n",
    "#     atomic_claim: str,\n",
    "# ) -> bool:\n",
    "#     \"\"\"\n",
    "#     For a claim to be relevant, it must be:\n",
    "#         (1) Supported by the example.\n",
    "#         (2) Answers the question of why the LLM gave the answer it did for this specific example.\n",
    "\n",
    "#     Args:\n",
    "#         example (str | Image | timeseries): The input example from a dataset from which to distill the relevant features from.\n",
    "#         answer (str): The LLM-generated answer to the example.\n",
    "#         atomic_claim (str): A claim to check if it is relevant to the example.\n",
    "#     \"\"\"\n",
    "\n",
    "answer = llm_generated_answer\n",
    "atomic_claim = raw_atomic_claims[0]\n",
    "\n",
    "system_prompt_is_claim_relevant = \"\"\"You are an expert cosmologist. You need to check if a claim is relevant to the image of weak lensing map or not.\n",
    "For a claim to be relevant, it must be:\n",
    "(1) Supported by the example.\n",
    "(2) Answers the question of why the LLM gave the answer it did for this specific example.\n",
    "\n",
    "Please only answer YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "prompt_is_claim_relevant = \"\"\"Answer:\n",
    "{}\n",
    "\n",
    "Atomic Claim:\n",
    "{}\n",
    "\"\"\".format(answer, atomic_claim)\n",
    "\n",
    "get_llm_score(prompt_is_claim_relevant, \n",
    "              images=[image_pil], \n",
    "              system_prompt=system_prompt_is_claim_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f60074c7-68b0-4245-80f3-3545ca823897",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('yes', 0.9998760879914247)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def is_claim_relevant(\n",
    "#     example: str | torch.Tensor,\n",
    "#     answer: str,\n",
    "#     atomic_claim: str,\n",
    "# ) -> bool:\n",
    "#     \"\"\"\n",
    "#     For a claim to be relevant, it must be:\n",
    "#         (1) Supported by the example.\n",
    "#         (2) Answers the question of why the LLM gave the answer it did for this specific example.\n",
    "\n",
    "#     Args:\n",
    "#         example (str | Image | timeseries): The input example from a dataset from which to distill the relevant features from.\n",
    "#         answer (str): The LLM-generated answer to the example.\n",
    "#         atomic_claim (str): A claim to check if it is relevant to the example.\n",
    "#     \"\"\"\n",
    "\n",
    "answer = llm_generated_answer\n",
    "atomic_claim = raw_atomic_claims[0]\n",
    "\n",
    "system_prompt_is_claim_relevant = \"\"\"You are an expert cosmologist. You need to check if a claim is relevant to the image of weak lensing map or not.\n",
    "For a claim to be relevant, it must be:\n",
    "(1) Supported by the example.\n",
    "(2) Answers the question of why the LLM gave the answer it did for this specific example.\n",
    "\n",
    "Please only answer YES or NO.\n",
    "\"\"\"\n",
    "\n",
    "prompt_is_claim_relevant = \"\"\"Answer:\n",
    "{}\n",
    "\n",
    "Atomic Claim:\n",
    "{}\n",
    "\"\"\".format(answer, atomic_claim)\n",
    "\n",
    "get_llm_score(prompt_is_claim_relevant, \n",
    "              images=[image_pil], \n",
    "              system_prompt=system_prompt_is_claim_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "91bd53f0-d050-45e3-bd0a-a841688262ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Claims:\\n```json\\n[\\n    \"In a weak lensing map, the distribution of dark matter can be inferred from the distortion of background galaxies due to gravitational lensing.\",\\n    \"The presence of structures, such as clusters and filaments, indicates the underlying matter distribution.\",\\n    \"From the weak lensing map, we can estimate the values of \\\\(\\\\Omega_m\\\\) (the matter density parameter) and \\\\(\\\\sigma_8\\\\) (the amplitude of density fluctuations).\",\\n    \"A higher density of dark matter structures suggests a larger \\\\(\\\\Omega_m\\\\).\",\\n    \"The degree of clustering in the weak lensing map informs us about \\\\(\\\\sigma_8\\\\).\",\\n    \"If the map shows significant clustering and pronounced features, we might predict \\\\(\\\\Omega_m\\\\) to be around 0.3 to 0.4.\",\\n    \"A prediction of \\\\(\\\\Omega_m\\\\) around 0.3 to 0.4 indicates a substantial amount of matter in the universe.\",\\n    \"If the structures in the map appear tightly clustered, values of \\\\(\\\\sigma_8\\\\) around 0.8 to 0.9 could be inferred.\",\\n    \"A high amplitude of fluctuations is reflected by values of \\\\(\\\\sigma_8\\\\) around 0.8 to 0.9.\",\\n    \"A more diffuse distribution of structures in the map would suggest lower values of \\\\(\\\\sigma_8\\\\).\",\\n    \"Analyzing the density and distribution of features in the weak lensing map allows us to make cosmological predictions.\"\\n]\\n```'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt_text2claims = \"\"\"You are an expert cosmologist. This is the explanation and answer for predicting from mass maps. Please break it down into atomic claims.\n",
    "Output format:\n",
    "Claims:\n",
    "```json\n",
    "[\n",
    "    \"<claim 1>\",\n",
    "    \"<claim 2>\",\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "raw_atomic_claims = get_llm_output(llm_generated_answer, system_prompt=system_prompt_text2claims)\n",
    "raw_atomic_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94f4eedc-7a20-4e9d-bf5b-880f60abef48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. In a weak lensing map, the distribution of dark matter can be inferred from the distortion of background galaxies due to gravitational lensing.',\n",
       " '',\n",
       " '2. The presence of structures, such as clusters and filaments, indicates the underlying matter distribution.',\n",
       " '',\n",
       " '3. From the weak lensing map, we can estimate the values of \\\\(\\\\Omega_m\\\\) (the matter density parameter).',\n",
       " '',\n",
       " '4. We can also estimate the value of \\\\(\\\\sigma_8\\\\) (the amplitude of density fluctuations) from the weak lensing map.',\n",
       " '',\n",
       " '5. A higher density of dark matter structures suggests a larger value of \\\\(\\\\Omega_m\\\\).',\n",
       " '',\n",
       " '6. The degree of clustering in the map informs us about the value of \\\\(\\\\sigma_8\\\\).',\n",
       " '',\n",
       " '7. If the map shows significant clustering and pronounced features, we might predict \\\\(\\\\Omega_m\\\\) to be around 0.3 to 0.4.',\n",
       " '',\n",
       " '8. A predicted \\\\(\\\\Omega_m\\\\) value of 0.3 to 0.4 indicates a substantial amount of matter in the universe.',\n",
       " '',\n",
       " '9. If the structures in the map appear tightly clustered, values of \\\\(\\\\sigma_8\\\\) around 0.8 to 0.9 could be inferred.',\n",
       " '',\n",
       " '10. A \\\\(\\\\sigma_8\\\\) value of 0.8 to 0.9 reflects a high amplitude of fluctuations.',\n",
       " '',\n",
       " '11. Conversely, a more diffuse distribution of structures would suggest lower values of \\\\(\\\\Omega_m\\\\) and \\\\(\\\\sigma_8\\\\).',\n",
       " '',\n",
       " '12. Analyzing the density and distribution of features in the weak lensing map allows us to make these cosmological predictions.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_atomic_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1380c74-7854-48cb-aa5f-276d936b6ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
