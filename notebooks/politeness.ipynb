{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import importlib\n",
    "import sys; sys.path.append(\"../src\")\n",
    "import politeness\n",
    "importlib.reload(politeness)\n",
    "from politeness import PolitenessExample, get_llm_generated_answer, isolate_individual_features, distill_relevant_features, calculate_expert_alignment_score, run_pipeline, load_politeness_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Politeness Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_data =  load_dataset(\"BrachioLab/multilingual_politeness\")\n",
    "politeness_data = politeness_data['train'].to_pandas()\n",
    "politeness_data = politeness_data[politeness_data['language'] == \"english\"].sample(1, random_state=11).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_data['Utterance'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 0: Get LLM Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_examples = []\n",
    "for idx,row in tqdm(politeness_data.iterrows()):\n",
    "    rating, explanation = get_llm_generated_answer(row['Utterance'], \"subq\")\n",
    "    if rating is None:\n",
    "        continue\n",
    "    politeness_examples.append(PolitenessExample(\n",
    "        utterance=row['Utterance'],\n",
    "        ground_truth=float(row['politeness']) + 3,\n",
    "        llm_score=rating,\n",
    "        llm_explanation=explanation\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_examples[0].llm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_examples[0].llm_explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Atomic claim extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in politeness_examples:\n",
    "    claims = isolate_individual_features(example.llm_explanation)\n",
    "    if claims is None:\n",
    "        continue\n",
    "    example.claims = [claim.strip() for claim in claims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_examples[0].claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Distill relevant claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in politeness_examples:\n",
    "    relevant_claims = distill_relevant_features(example)\n",
    "    example.relevant_claims = relevant_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_examples[0].relevant_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3: Calculate alignment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in politeness_examples:\n",
    "    alignment_scores = []\n",
    "    alignment_categories = []\n",
    "    for claim in tqdm(example.relevant_claims):\n",
    "        category, alignment_score, reasoning = calculate_expert_alignment_score(claim)\n",
    "        if category is None:\n",
    "            continue\n",
    "        alignment_scores.append(alignment_score)\n",
    "        alignment_categories.append(category)\n",
    "    example.alignment_scores = alignment_scores\n",
    "    example.alignment_categories = alignment_categories\n",
    "    example.final_alignment_score = np.mean(alignment_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_examples[0].alignment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_examples[0].alignment_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_examples[0].final_alignment_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
