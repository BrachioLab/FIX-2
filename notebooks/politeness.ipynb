{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyah/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from diskcache import Cache\n",
    "cache = Cache(\"/shared_data0/llm_cachedir\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Querying Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache.memoize()\n",
    "def query_openai(prompt, model=\"gpt-4o\"):\n",
    "    with open(\"../API_KEY.txt\", \"r\") as file:\n",
    "        api_key = file.read()\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    num_tries = 0\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            translation = client.chat.completions.create(\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }],\n",
    "                model=model,\n",
    "            )\n",
    "            return translation.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            num_tries += 1\n",
    "            print(\"Try {}; Error: {}\".format(str(num_tries), str(e)))     \n",
    "            time.sleep(3)\n",
    "    return \"ERROR\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Politeness Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_data =  load_dataset(\"BrachioLab/multilingual_politeness\")\n",
    "politeness_data = politeness_data['train'].to_pandas()\n",
    "politeness_data = politeness_data[politeness_data['language'] == \"english\"].sample(3, random_state=11).reset_index(drop=True)\n",
    "\n",
    "class PolitenessExample:\n",
    "    def __init__(self, utterance, ground_truth, llm_score, llm_explanation):\n",
    "        self.utterance = utterance\n",
    "        self.ground_truth = ground_truth\n",
    "        self.llm_score = llm_score\n",
    "        self.llm_explanation = llm_explanation\n",
    "        self.claims = []\n",
    "        self.relevant_claims = []\n",
    "        self.alignment_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This talk page is not the 2004 film version, this page is based on the story. But anyway, the film was great. I think some people are too critical about some things.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_data['Utterance'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 0: Get LLM Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 198.61it/s]\n"
     ]
    }
   ],
   "source": [
    "explanation_prompt = \"\"\"What is the politeness of the following utterance? Use the following 1-5 scale:\n",
    "1: extremely rude\n",
    "2: somewhat rude\n",
    "3: neutral\n",
    "4: somewhat polite\n",
    "5: extremely polite\n",
    "\n",
    "In addition, provide a paragraph explaining why you gave the utterance that rating. Your response should be 2 lines, formatted as follows:\n",
    "Rating: <rating>\n",
    "Explanation: <explanation>\n",
    "\n",
    "Utterance: {}\n",
    "\"\"\"\n",
    "def get_llm_generated_answer(utterance: str):\n",
    "    prompt = explanation_prompt.format(utterance)\n",
    "    response = query_openai(prompt)\n",
    "    if response == \"ERROR\":\n",
    "        print(\"Error in querying OpenAI API\")\n",
    "        return None\n",
    "    rating = response.split(\"\\n\")[0].split(\"Rating: \")[1].strip()\n",
    "    explanation = response.split(\"\\n\")[1].split(\"Explanation: \")[1].strip()\n",
    "    return rating, explanation\n",
    "\n",
    "politeness_examples = []\n",
    "for idx,row in tqdm(politeness_data.iterrows()):\n",
    "    rating, explanation = get_llm_generated_answer(row['Utterance'])\n",
    "    if rating is None:\n",
    "        continue\n",
    "    politeness_examples.append(PolitenessExample(\n",
    "        utterance=row['Utterance'],\n",
    "        ground_truth=float(row['politeness']) + 3,\n",
    "        llm_score=rating,\n",
    "        llm_explanation=explanation\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].llm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The utterance is neutral as it provides clarification and expresses a personal opinion without using overtly polite or rude language. It acknowledges a difference without disrespect, although it lacks elements of politeness like gratitude or praise.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].llm_explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Atomic claim extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_prompt = \"\"\"\n",
    "You will be given a paragraph that explains why a certain level of politeness was attributed to an utterance. Your task is to decompose this explanation into individual claims that are:\n",
    "\n",
    "Atomic: Each claim should express only one clear idea or judgment.\n",
    "Standalone: Each claim should be self-contained and understandable without needing to refer back to the paragraph.\n",
    "Faithful: The claims must preserve the original meaning, nuance, and tone. Do not omit hedging language (e.g., \"seems to,\" \"somewhat,\" \"lacks overt markers\") or subjective phrasing if present.\n",
    "\n",
    "Format your output as a list of claims separated by new lines. Do not include any additional text or explanations.\n",
    "\n",
    "Here is an example of how to format your output:\n",
    "\n",
    "INPUT: This utterance is formal and professional, with no overtly rude language. The phrasing is neutral-to-polite, as it avoids accusatory or dismissive tones. The use of \"I am copying them here\" is transparent and non-confrontational, and \"seem to constitute\" softens any potential imposition by acknowledging some level of subjectivity. However, it lacks explicit politeness markers such as \"please\" or \"thank you,\" which would elevate it to \"extremely polite.\"\n",
    "\n",
    "OUTPUT:\n",
    "The utterance is formal and professional.\n",
    "The utterance contains no overtly rude language.\n",
    "The phrasing is neutral-to-polite because it avoids accusatory or dismissive tones.\n",
    "The phrase \"I am copying them here\" is transparent and non-confrontational.\n",
    "The phrase \"seem to constitute\" softens any potential imposition by acknowledging subjectivity.\n",
    "The utterance lacks explicit politeness markers such as \"please\" or \"thank you.\"\n",
    "The lack of explicit politeness markers prevents the utterance from being considered \"extremely polite.\"\n",
    "\n",
    "Now decompose the following paragraph into atomic, standalone claims:\n",
    "INPUT: {}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def isolate_individual_features(explanation: str):\n",
    "    prompt = claim_prompt.format(explanation)\n",
    "    response = query_openai(prompt)\n",
    "    if response == \"ERROR\":\n",
    "        print(\"Error in querying OpenAI API\")\n",
    "        return None\n",
    "    response = response.replace(\"OUTPUT:\", \"\").strip()\n",
    "    claims = response.split(\"\\n\")\n",
    "    return claims\n",
    "\n",
    "for example in politeness_examples:\n",
    "    claims = isolate_individual_features(example.llm_explanation)\n",
    "    if claims is None:\n",
    "        continue\n",
    "    example.claims = [claim.strip() for claim in claims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The utterance is neutral.',\n",
       " 'The utterance provides clarification.',\n",
       " 'The utterance expresses a personal opinion.',\n",
       " 'The utterance does not use overtly polite language.',\n",
       " 'The utterance does not use overtly rude language.',\n",
       " 'The utterance acknowledges a difference without disrespect.',\n",
       " 'The utterance lacks elements of politeness such as gratitude.',\n",
       " 'The utterance lacks elements of politeness such as praise.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Distill relevant claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 562.18it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 690.86it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 1134.70it/s]\n"
     ]
    }
   ],
   "source": [
    "relevance_prompt = \"\"\"You will be given an utterance, its politeness rating on a 1-5 scale (where 1: very rude and 5: very polite), and a claim that may or may not be relevant to an explanation of the rating. Your task is to decide whether the claim is relevant to explaining the politeness rating for this specific utterance.\n",
    "\n",
    "A claim is relevant if and only if:\n",
    "(1) It is supported by the content of the utterance (i.e., it does not hallucinate or speculate beyond what is said).\n",
    "(2) It helps explain why the utterance received the given politeness rating (i.e., it directly relates to tone, phrasing, or other aspects relevant to the rating).\n",
    "\n",
    "Return your answer as:\n",
    "Relevance: <Yes/No>\n",
    "Reasoning: <A brief explanation of your judgment, pointing to specific support or lack thereof>\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "[Example 1]\n",
    "Utterance: \"There is no such fact - you are just making things up. There is no reason to believe that any person reading about Bologna would be particularly interested in Kappa Sigma. If they wanted to know about Kappa Sigma, they would read the Kappa Sigma article instead..\"\n",
    "Politeness Rating: 2\n",
    "Claim: The utterance accuses the other person of fabricating information.\n",
    "Relevance: Yes\n",
    "Reasoning: The claim is relevant because it discusses the accusatory tone of the utterance, which contributes to its rudeness classification.\n",
    "\n",
    "[Example 2]\n",
    "Utterance: \"Deleted reference to REM sleep in the first sentence. It simply is not true. In fact, REM deprivation is a common side effect of antidepressant use (some attribute their effects to REM deprivation).\"\n",
    "Politeness Rating: 3\n",
    "Claim: The utterance is neutral.\n",
    "Relevance: No\n",
    "Reasoning: The claim is not relevant because it simply states the rating, and does not provide information about why the rating was given. Claims that merely state the rating are not relevant.\n",
    "\n",
    "[Example 3]\n",
    "Utterance: \"Tetra-gram is a compound word as is the penta-gram. Penta refers to the number 5 in Greek, tetra refers to the number 4 and gram refers to the word line in both cases. Obviously a star shape can't be shaped with 4 lines.\"\n",
    "Politeness Rating: 3\n",
    "Claim: The use of \"obviously\" might suggest the author is an expert in Greek.\n",
    "Relevance: No\n",
    "Reasoning: The claim is not relevant because there is nothing in the text to support that the author may be Greek. \n",
    "\n",
    "Now, determine whether the following claim is relevant to the given utterance and politeness rating:\n",
    "Utterance: {}\n",
    "Politeness Rating: {}\n",
    "Claim: {}\n",
    "\"\"\"\n",
    "\n",
    "def is_claim_relevant(utterance: str, rating: str, claim: str):\n",
    "    prompt = relevance_prompt.format(utterance, rating, claim)\n",
    "    response = query_openai(prompt)\n",
    "    if response == \"ERROR\":\n",
    "        print(\"Error in querying OpenAI API\")\n",
    "        return None\n",
    "    response = response.replace(\"Relevance:\", \"\").strip()\n",
    "    response = response.split(\"\\n\")\n",
    "    relevance = response[0].strip()\n",
    "    reasoning = response[1].replace(\"Reasoning:\", \"\").strip()\n",
    "    return relevance, reasoning\n",
    "\n",
    "\n",
    "def distill_relevant_features(example: PolitenessExample):\n",
    "    relevant_claims = []\n",
    "    for claim in tqdm(example.claims):\n",
    "        relevance, reasoning = is_claim_relevant(example.utterance, example.llm_score, claim)\n",
    "        if relevance is None:\n",
    "            continue\n",
    "        if relevance == \"Yes\":\n",
    "            relevant_claims.append(claim)\n",
    "    return relevant_claims\n",
    "\n",
    "for example in politeness_examples:\n",
    "    relevant_claims = distill_relevant_features(example)\n",
    "    example.relevant_claims = relevant_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The utterance provides clarification.',\n",
       " 'The utterance expresses a personal opinion.',\n",
       " 'The utterance does not use overtly polite language.',\n",
       " 'The utterance does not use overtly rude language.',\n",
       " 'The utterance acknowledges a difference without disrespect.',\n",
       " 'The utterance lacks elements of politeness such as gratitude.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].relevant_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3: Calculate alignment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 1336.40it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1679.74it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1679.23it/s]\n"
     ]
    }
   ],
   "source": [
    "alignment_prompt = \"\"\"You will be given an utterance, its politeness rating on a 1-5 scale (where 1: very rude and 5: very polite), and a claim that relates to why that rating was given. You will also be given a series of lexical categories that relate to politeness.\n",
    "\n",
    "Your task is as follows:\n",
    "1. Determine which lexical category is most aligned with the claim. \n",
    "2. Rate how strongly the category aligns with the claim on a scale of 1-5 (1 being lowest, 5 being highest). \n",
    "\n",
    "Return your answer as:\n",
    "Category: <category>\n",
    "Category Alignment Rating: <rating>\n",
    "Reasoning: <A brief explanation of why you selected the chosen category and why you judged the alignment rating as you did.>\n",
    "\n",
    "-----\n",
    "Lexical categories:\n",
    "1. Apologetic: Words and phrases used to acknowledge mistakes or express regret. (sorry, woops, oops, sry, apologize)\n",
    "2. Deference: Polite words that convey respect, admiration, or acknowledgment of someone's status or authority. (great, good, nice, interesting, cool)\n",
    "3. Direct Question: Words commonly used to form explicit questions seeking information or clarification. (what, where, why, who, when)\n",
    "4. Discourse Marker: Common transition words used to structure speech or writing. (so, then, and, but, or)\n",
    "5. Emergency: Phrases indicating urgency, immediate attention, or emergency situations. (right now, rn, as soon as possible, asap, immediately)\n",
    "6. Factuality: Expressions that assert factual information or emphasize reality. (in fact, actually, the point, the reality, the truth)\n",
    "7. First Person Plural: Sentences that contain a first-person plural pronoun. (we, our, ours, us, ourselves)\n",
    "8. First Person Singular: Sentences that contain a first-person singular pronoun. (I, my, mine, myself, me)\n",
    "9. First Person Start: Sentences that begin with a first-person singular pronoun. (I, my, mine, myself)\n",
    "10. Gratitude: Words and phrases that express appreciation and thankfulness. (thanks, thx, thank you, thank u, i appreciate)\n",
    "11. Greeting: Words and phrases used to initiate interaction or acknowledge someone’s presence. (hi, hello, hey)\n",
    "12. Negative Emotion: Words and expressions that convey strong negative emotions or discontent. (bullshit, fuck, fucking, damn, shit)\n",
    "13. Positive Emotion: Words and expressions that convey happiness, excitement, or approval. (abound, prefer, pride, priceless, pretty)\n",
    "14. Hedging: Words that soften statements, making them less direct or assertive. (think, usually, unclearly, unclear, uncertainly)\n",
    "15. Directive Speech Act: Expressions that instruct, command, or request an action from the listener. (can you, will you, can u, will u)\n",
    "16. Indirectness: Words that introduce indirectness in communication, often for politeness or subtlety. (btw, by the way)\n",
    "17. Ingroup Identity: Words that signal belonging to a specific social group or community. (mate, bro, homie, dude)\n",
    "18. Politeness Marker: Words that make a request or instruction more courteous. (please, pls, plz, plse)\n",
    "19. Polite Start: Sentences that begin with a politeness marker. (please, pls, plz)\n",
    "20. Praise: Expressions that convey approval, admiration, or compliments. (awesome, outstanding, excellent, great, neat)\n",
    "21. Commitment Marker: Words that express certainty or a strong commitment to an action or belief. (must, definitely, sure, definite, surely)\n",
    "22. Second Person: Sentences that contain a second-person pronoun. (you, your, yours, yourself, u)\n",
    "23. Second Person Start: Sentences that begin with a second-person pronoun. (you, your, yours, yourself)\n",
    "24. Polite Request: Phrases that express politeness in requests or suggestions using modal verbs. (could you, would you, could u, would u)\n",
    "25. Togetherness: Words that emphasize unity, collective action, or inclusivity. (together)\n",
    "26. Direct Address: Words directly addressing the listener in conversation. (you, u)\n",
    "-----\n",
    "\n",
    "Here are some examples:\n",
    "[Example 1]\n",
    "Utterance: \"There is no such fact - you are just making things up. There is no reason to believe that any person reading about Bologna would be particularly interested in Kappa Sigma. If they wanted to know about Kappa Sigma, they would read the Kappa Sigma article instead..\"\n",
    "Politeness Rating: 2\n",
    "Claim: The utterance accuses the other person of fabricating information.\n",
    "Category: Negative Emotion\n",
    "Category Alignment Rating: 4\n",
    "Reasoning: The accusatory tone and claim of fabrication imply a confrontational or hostile interaction, which strongly aligns with negative emotion. While the emotion is more implicit than explicit profanity or insult, the accusatory framing still carries a strong negative charge.\n",
    "\n",
    "[Example 2]\n",
    "Utterance: \"Deleted reference to REM sleep in the first sentence. It simply is not true. In fact, REM deprivation is a common side effect of antidepressant use (some attribute their effects to REM deprivation).\"\n",
    "Politeness Rating: 3\n",
    "Claim: The sentence structure is overly complex and difficult to follow.\n",
    "Category: Discourse Marker\n",
    "Category Alignment Rating: 1\n",
    "Reasoning: The claim is about sentence complexity and structure, which does not relate to any of the listed lexical categories, including Discourse Marker, which refers to specific connecting words like “so” or “but.” The utterance does not exhibit structural markers that would directly contribute to complexity based on the provided categories, making the alignment very weak.\n",
    "\n",
    "[Example 3]\n",
    "Utterance: \"Tetra-gram is a compound word as is the penta-gram. Penta refers to the number 5 in Greek, tetra refers to the number 4 and gram refers to the word line in both cases. Obviously a star shape can't be shaped with 4 lines.\"\n",
    "Politeness Rating: 3\n",
    "Claim: The use of \"obviously\" might suggest a slight assumption of common knowledge.\n",
    "Category: Factuality\n",
    "Category Alignment Rating: 3\n",
    "Reasoning: The utterance presents factual information about word origins and geometric logic, and the claim focuses on the use of \"obviously,\" which implies assumed knowledge rather than asserting a fact. This aligns somewhat with Factuality, but not strongly—Factuality is involved, but the assumption of common knowledge is more about tone than fact.\n",
    "\n",
    "Now, determine the category and alignment rating for the following claim:\n",
    "Utterance: {}\n",
    "Politeness Rating: {}\n",
    "Claim: {}\n",
    "\"\"\"\n",
    "\n",
    "def calculate_expert_alignment_score(utterance: str, rating: str, claim: str):\n",
    "    prompt = alignment_prompt.format(utterance, rating, claim)\n",
    "    response = query_openai(prompt)\n",
    "    if response == \"ERROR\":\n",
    "        print(\"Error in querying OpenAI API\")\n",
    "        return None\n",
    "    response = response.replace(\"Category:\", \"\").strip()\n",
    "    response = response.split(\"\\n\")\n",
    "    category = response[0].strip()\n",
    "    alignment_score = response[1].replace(\"Category Alignment Rating:\", \"\").strip()\n",
    "    reasoning = response[2].replace(\"Reasoning:\", \"\").strip()\n",
    "    return category, alignment_score, reasoning\n",
    "\n",
    "for example in politeness_examples:\n",
    "    alignment_scores = []\n",
    "    alignment_categories = []\n",
    "    for claim in tqdm(example.relevant_claims):\n",
    "        category, alignment_score, reasoning = calculate_expert_alignment_score(example.utterance, example.llm_score, claim)\n",
    "        if category is None:\n",
    "            continue\n",
    "        alignment_scores.append(alignment_score)\n",
    "        alignment_categories.append(category)\n",
    "    example.alignment_scores = alignment_scores\n",
    "    example.alignment_categories = alignment_categories\n",
    "    example.final_alignment = np.mean([float(score) for score in alignment_scores])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4', '4', '2', '1', '4', '4']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].alignment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Factuality',\n",
       " 'First Person Singular',\n",
       " 'Hedging',\n",
       " 'Negative Emotion',\n",
       " 'Hedging',\n",
       " 'Gratitude']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].alignment_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1666666666666665"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].final_alignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
