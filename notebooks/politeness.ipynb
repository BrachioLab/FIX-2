{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import importlib\n",
    "import sys; sys.path.append(\"../src\")\n",
    "import politeness\n",
    "importlib.reload(politeness)\n",
    "from politeness import PolitenessExample, get_llm_generated_answer, isolate_individual_features, distill_relevant_features, calculate_expert_alignment_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Politeness Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "politeness_data =  load_dataset(\"BrachioLab/multilingual_politeness\")\n",
    "politeness_data = politeness_data['train'].to_pandas()\n",
    "politeness_data = politeness_data[politeness_data['language'] == \"english\"].sample(3, random_state=11).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This talk page is not the 2004 film version, this page is based on the story. But anyway, the film was great. I think some people are too critical about some things.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_data['Utterance'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 0: Get LLM Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:05,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "politeness_examples = []\n",
    "for idx,row in tqdm(politeness_data.iterrows()):\n",
    "    rating, explanation = get_llm_generated_answer(row['Utterance'])\n",
    "    if rating is None:\n",
    "        continue\n",
    "    politeness_examples.append(PolitenessExample(\n",
    "        utterance=row['Utterance'],\n",
    "        ground_truth=float(row['politeness']) + 3,\n",
    "        llm_score=rating,\n",
    "        llm_explanation=explanation\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].llm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The utterance is neutral because it presents facts relating to a discussion about a film, while also offering a personal opinion without explicitly demeaning or offending others.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].llm_explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: Atomic claim extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for example in politeness_examples:\n",
    "    claims = isolate_individual_features(example.llm_explanation)\n",
    "    if claims is None:\n",
    "        continue\n",
    "    example.claims = [claim.strip() for claim in claims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The utterance is neutral.',\n",
       " 'The utterance presents facts related to a film discussion.',\n",
       " 'The utterance includes a personal opinion.',\n",
       " 'The personal opinion offered in the utterance does not explicitly demean or offend others.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Distill relevant claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.77s/it]\n",
      "100%|██████████| 6/6 [00:16<00:00,  2.70s/it]\n",
      "100%|██████████| 5/5 [00:13<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "for example in politeness_examples:\n",
    "    relevant_claims = distill_relevant_features(example)\n",
    "    example.relevant_claims = relevant_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The utterance presents facts related to a film discussion.',\n",
       " 'The utterance includes a personal opinion.',\n",
       " 'The personal opinion offered in the utterance does not explicitly demean or offend others.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].relevant_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 3: Calculate alignment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:08<00:00,  2.82s/it]\n",
      "100%|██████████| 6/6 [00:17<00:00,  2.89s/it]\n",
      "100%|██████████| 3/3 [00:14<00:00,  4.95s/it]\n"
     ]
    }
   ],
   "source": [
    "for example in politeness_examples:\n",
    "    alignment_scores = []\n",
    "    alignment_categories = []\n",
    "    for claim in tqdm(example.relevant_claims):\n",
    "        category, alignment_score, reasoning = calculate_expert_alignment_score(claim)\n",
    "        if category is None:\n",
    "            continue\n",
    "        alignment_scores.append(alignment_score)\n",
    "        alignment_categories.append(category)\n",
    "    example.alignment_scores = alignment_scores\n",
    "    example.alignment_categories = alignment_categories\n",
    "    example.final_alignment = np.mean(alignment_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2, 0.9, 0.8]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].alignment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Discourse Management with Markers',\n",
       " 'First-Person Subjectivity Markers',\n",
       " 'First-Person Subjectivity Markers']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].alignment_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8200000000000001"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politeness_examples[0].final_alignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
