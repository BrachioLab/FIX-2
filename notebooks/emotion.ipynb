{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e000caa4-0301-402f-916e-86f9a1fec6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from diskcache import Cache\n",
    "# cache = Cache(\"/shared_data0/llm_cachedir\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c78546-f9b8-46c0-8013-54e2cc22d4ab",
   "metadata": {},
   "source": [
    "### OpenAI Querying Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59a48e0-4760-43e9-83a9-391199c4ac63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @cache.memoize()\n",
    "def query_openai(prompt, model=\"gpt-4o\"):\n",
    "    with open(\"../API_KEY.txt\", \"r\") as file:\n",
    "        api_key = file.read()\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    num_tries = 0\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            translation = client.chat.completions.create(\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt,\n",
    "                }],\n",
    "                model=model,\n",
    "            )\n",
    "            return translation.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            num_tries += 1\n",
    "            print(\"Try {}; Error: {}\".format(str(num_tries), str(e)))     \n",
    "            time.sleep(3)\n",
    "    return \"ERROR\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699b4b7-7179-415c-b94c-63705eb27214",
   "metadata": {},
   "source": [
    "### Load Emotion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6604f849-5d96-4f2d-bf97-7edabe0163ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_data =  load_dataset(\"BrachioLab/emotion\")\n",
    "emotion_data = emotion_data['train'].to_pandas()\n",
    "emotion_data = emotion_data.sample(10, random_state=11).reset_index(drop=True)\n",
    "\n",
    "class EmotionExample:\n",
    "    def __init__(self, text, ground_truth, llm_label, llm_explanation):\n",
    "        self.text = text\n",
    "        self.ground_truth = ground_truth\n",
    "        self.llm_label = llm_label\n",
    "        self.llm_explanation = llm_explanation\n",
    "        self.claims = []\n",
    "        self.relevant_claims = []\n",
    "        self.alignment_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92c7cc5-8eb8-4f15-8be2-a161cb529fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "emotion_labels = {\n",
    "    0: \"admiration\",\n",
    "    1: \"amusement\",\n",
    "    2: \"anger\",\n",
    "    3: \"annoyance\",\n",
    "    4: \"approval\",\n",
    "    5: \"caring\",\n",
    "    6: \"confusion\",\n",
    "    7: \"curiosity\",\n",
    "    8: \"desire\",\n",
    "    9: \"disappointment\",\n",
    "    10: \"disapproval\",\n",
    "    11: \"disgust\",\n",
    "    12: \"embarrassment\",\n",
    "    13: \"excitement\",\n",
    "    14: \"fear\",\n",
    "    15: \"gratitude\",\n",
    "    16: \"grief\",\n",
    "    17: \"joy\",\n",
    "    18: \"love\",\n",
    "    19: \"nervousness\",\n",
    "    20: \"optimism\",\n",
    "    21: \"pride\",\n",
    "    22: \"realization\",\n",
    "    23: \"relief\",\n",
    "    24: \"remorse\",\n",
    "    25: \"sadness\",\n",
    "    26: \"surprise\",\n",
    "    27: \"neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d8e72-555a-4704-b64a-e4ee3e33f1db",
   "metadata": {},
   "source": [
    "### Stage 0: Get LLM Explanations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3029a222-7398-4eeb-b31c-0d3724b15796",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:08,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "explanation_prompt = \"\"\"What is the emotion of the following text? Here are the possible labels you could use:\n",
    "admiration\n",
    "amusement\n",
    "anger\n",
    "annoyance\n",
    "approval\n",
    "caring\n",
    "confusion\n",
    "curiosity\n",
    "desire\n",
    "disappointment\n",
    "disapproval\n",
    "disgust\n",
    "embarrassment\n",
    "excitement\n",
    "fear\n",
    "gratitude\n",
    "grief\n",
    "joy\n",
    "love\n",
    "nervousness\n",
    "optimism\n",
    "pride\n",
    "realization\n",
    "relief\n",
    "remorse\n",
    "sadness\n",
    "surprise\n",
    "neutral\n",
    "\n",
    "In addition, provide a paragraph explaining why you gave the text that classification label. Your response should be 2 lines, formatted as follows:\n",
    "Label: <label>\n",
    "Explanation: <explanation>\n",
    "\n",
    "Here is the following text.\n",
    "Text: {}\n",
    "\"\"\"\n",
    "def get_llm_generated_answer(text: str):\n",
    "    prompt = explanation_prompt.format(text)\n",
    "    response = query_openai(prompt)\n",
    "    if response == \"ERROR\":\n",
    "        print(\"Error in querying OpenAI API\")\n",
    "        return None\n",
    "    response_split = [e for e in response.split(\"\\n\") if (e != '' and e.split()[0] in ['Label:', 'Explanation:'])]\n",
    "    llm_label = response_split[0].split(\"Label: \")[1].strip()\n",
    "    explanation = response_split[1].split(\"Explanation: \")[1].strip()\n",
    "    return llm_label, explanation\n",
    "\n",
    "emotion_examples = []\n",
    "for idx,row in tqdm(emotion_data.iterrows()):\n",
    "    llm_label, explanation = get_llm_generated_answer(row['text'])\n",
    "    if llm_label is None:\n",
    "        continue\n",
    "    emotion_examples.append(EmotionExample(\n",
    "        text=row['text'],\n",
    "        ground_truth=emotion_labels[row['labels'][0]],\n",
    "        llm_label=llm_label,\n",
    "        llm_explanation=explanation\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f333bf-5eb5-4b83-8224-b0c5f1dd7a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[emotion_examples[i].llm_label for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0edc98b2-cb9a-47fe-b400-f2ed30641ebb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'neutral'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_examples[0].ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7878a2b4-6af5-4028-aff4-89d0f87984da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Creepy Yoda voicepack tbh'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_examples[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d3218ee-652f-403b-a162-51e8ca032aae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'annoyance'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_examples[0].llm_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9463a05e-9561-4bde-9ef6-939bd73b4546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The use of \"creepy\" along with \"tbh\" (to be honest) suggests a sentiment of annoyance or discomfort with the Yoda voicepack, showing dissatisfaction with its portrayal.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_examples[0].llm_explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34cd288-4c9b-4156-b0ac-e0d4e03d6a83",
   "metadata": {},
   "source": [
    "### Stage 1: Atomic claim extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37fb897d-892a-428f-bc34-f06ad30f60c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "claim_prompt = \"\"\"\n",
    "You will be given a paragraph that explains why a emotion was attributed to an utterance. Your task is to decompose this explanation into individual claims that are:\n",
    "\n",
    "Atomic: Each claim should express only one clear idea or judgment.\n",
    "Standalone: Each claim should be self-contained and understandable without needing to refer back to the paragraph.\n",
    "Faithful: The claims must preserve the original meaning, nuance, and tone. Do not omit hedging language (e.g., \"seems to,\" \"somewhat,\" \"lacks overt markers\") or subjective phrasing if present.\n",
    "\n",
    "Format your output as a list of claims separated by new lines. Do not include any additional text or explanations.\n",
    "\n",
    "Here is an example of how to format your output:\n",
    "\n",
    "INPUT: The use of \"creepy\" and \"tbh\" suggests a negative reaction or discomfort, likely indicating the speaker finds the voicepack irritating or unsettling.\n",
    "\n",
    "OUTPUT:\n",
    "\n",
    "The use of the word \"creepy\" suggests a negative reaction or discomfort.\n",
    "The word \"tbh\" likely indicates that the speaker finds the voicepack irritating or unsettling.\n",
    "\n",
    "Now decompose the following pararaph into atomic, standalone claims:\n",
    "INPUT: {}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def isolate_individual_features(explanation: str):\n",
    "    prompt = claim_prompt.format(explanation)\n",
    "    response = query_openai(prompt)\n",
    "    if response == \"ERROR\":\n",
    "        print(\"Error in querying OpenAI API\")\n",
    "        return None\n",
    "    response = response.replace(\"OUTPUT:\", \"\").strip()\n",
    "    claims = response.split(\"\\n\")\n",
    "    return claims\n",
    "\n",
    "for example in emotion_examples:\n",
    "    claims = isolate_individual_features(example.llm_explanation)\n",
    "    if claims is None:\n",
    "        continue\n",
    "    example.claims = [claim.strip() for claim in claims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6d39203-b482-4673-87e0-f01463281c32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The use of the word \"creepy\" suggests a sentiment of annoyance or discomfort.',\n",
       " 'The phrase \"tbh\" (to be honest) shows dissatisfaction with the Yoda voicepack.',\n",
       " 'The speaker is dissatisfied with the portrayal of the Yoda voicepack.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_examples[0].claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a155476e-ea49-44e1-98b7-51325075ebe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relevance_prompt = \"\"\"You will be given a text, its emotion label, and a claim that may or may not be relevant to an explanation of the emotion label. Your task is to decide whether the claim is relevant to explaining the emotion label for this specific text.\n",
    "\n",
    "A claim is relevant if and only if:\n",
    "(1) It is supported by the content of the utterance (i.e., it does not hallucinate or speculate beyond what is said).\n",
    "(2) It helps explain why the utterance received the given emotion label (i.e., it directly relates to tone, phrasing, or other aspects relevant to the label).\n",
    "\n",
    "Return your answer as:\n",
    "Relevance: <Yes/No>\n",
    "Reasoning: <A brief explanation of your judgment, pointing to specific support or lack thereof>\n",
    "\n",
    "Now, determine whether the following claim is relevant to the given text and emotion label:\n",
    "Text: {}\n",
    "Emotion Label: {}\n",
    "Claim: {}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62012051-1ae8-4420-8cd2-3169b6a10a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Creepy Yoda voicepack tbh\n",
      "Emotion Label: annoyance\n",
      "Claim: The use of the word \"creepy\" suggests a sentiment of annoyance or discomfort.\n",
      "Relevance: Yes  \n",
      "Reasoning: The claim is relevant because the use of the word \"creepy\" in the text can suggest a feeling of discomfort, which is consistent with the emotion label of annoyance. The term implies a negative sentiment that aligns with feeling annoyed by the Yoda voicepack.\n"
     ]
    }
   ],
   "source": [
    "prompt = relevance_prompt.format(emotion_examples[0].text, emotion_examples[0].llm_label, emotion_examples[0].claims[0])\n",
    "response = query_openai(prompt)\n",
    "print(\"Text:\", emotion_examples[0].text)\n",
    "print(\"Emotion Label:\", emotion_examples[0].llm_label)\n",
    "print(\"Claim:\", emotion_examples[0].claims[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01b1ea1a-f594-490b-983a-54845ebf92de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['annoyance',\n",
       " 'amusement',\n",
       " 'joy',\n",
       " 'approval',\n",
       " 'amusement',\n",
       " 'gratitude',\n",
       " 'approval',\n",
       " 'disapproval',\n",
       " 'amusement',\n",
       " 'annoyance']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[emotion_examples[i].llm_label for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "380a5653-d118-498e-89ea-8cb001e56f21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: This feels more like r/fellowkids to me. This is nothing compared to some of the more dystopian stuff the government has pushed out to be fair.\n",
      "Emotion Label: disapproval\n",
      "Claim: The text expresses a negative judgment about the content discussed.\n",
      "Relevance: Yes  \n",
      "Reasoning: The claim is relevant because the text indeed expresses a negative judgment, which aligns with the emotion label of disapproval. The use of phrases like \"This feels more like r/fellowkids to me\" and \"This is nothing compared to some of the more dystopian stuff the government has pushed out\" suggests a critical or dismissive tone towards the content being discussed. This supports the labeling of the emotion as disapproval.\n"
     ]
    }
   ],
   "source": [
    "prompt = relevance_prompt.format(emotion_examples[7].text, emotion_examples[7].llm_label, emotion_examples[7].claims[0])\n",
    "response = query_openai(prompt)\n",
    "print(\"Text:\", emotion_examples[7].text)\n",
    "print(\"Emotion Label:\", emotion_examples[7].llm_label)\n",
    "print(\"Claim:\", emotion_examples[7].claims[0])\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b69b9ba-363e-4f43-a511-db59795f3680",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Creepy Yoda voicepack tbh\n",
      "Emotion Label: amusement\n",
      "Claim: The use of \"creepy\" with \"Yoda voicepack\" indicates amusement at the concept.\n",
      "Relevance: Yes  \n",
      "Reasoning: The claim is relevant because it directly relates to the text's tone. The juxtaposition of \"creepy\" with \"Yoda voicepack\" suggests a humorous or lighthearted take on the concept. This tone aligns with the emotion label of amusement, indicating that the speaker finds the idea entertaining or funny, potentially because of the unexpected or absurd combination implied in the text. The claim helps explain why the emotion of amusement was attributed to the text.\n"
     ]
    }
   ],
   "source": [
    "prompt = relevance_prompt.format(emotion_examples[0].text, emotion_examples[0].llm_label, emotion_examples[0].claims[2])\n",
    "response = query_openai(prompt)\n",
    "print(\"Text:\", emotion_examples[0].text)\n",
    "print(\"Emotion Label:\", emotion_examples[0].llm_label)\n",
    "print(\"Claim:\", emotion_examples[0].claims[2])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf22385f-e0d2-4d70-b22b-cc31108ad031",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Motor Kombat was awesome. Goofy as hell, but awesome.\n",
      "Emotion Label: amusement\n",
      "Claim: The text expresses a sense of lighthearted enjoyment.\n",
      "Relevance: Yes  \n",
      "Reasoning: The claim that the text expresses a sense of lighthearted enjoyment is relevant to explaining the emotion label of amusement. The text's use of the words \"awesome\" and \"goofy\" indicates a sense of fun and enjoyment, and the phrase \"Goofy as hell, but awesome\" conveys a playful tone that aligns with amusement. Thus, the claim is supported by the content of the utterance and helps explain why it received the amusement label.\n"
     ]
    }
   ],
   "source": [
    "prompt = relevance_prompt.format(emotion_examples[1].text, emotion_examples[1].llm_label, emotion_examples[1].claims[0])\n",
    "response = query_openai(prompt)\n",
    "print(\"Text:\", emotion_examples[1].text)\n",
    "print(\"Emotion Label:\", emotion_examples[1].llm_label)\n",
    "print(\"Claim:\", emotion_examples[1].claims[0])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83d900dc-27e0-416f-bec9-d143e0e4a8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Motor Kombat was awesome. Goofy as hell, but awesome.\n",
      "Emotion Label: amusement\n",
      "Claim: There is an entertaining sentiment typically associated with amusement.\n",
      "Relevance: Yes  \n",
      "Reasoning: The claim is relevant because it accurately captures the tone of the text. The description of \"Motor Kombat\" as \"awesome\" and \"goofy as hell\" suggests an enjoyable and entertaining experience, which aligns with the entertaining sentiment associated with amusement. The text's phrasing supports the emotion label of amusement.\n"
     ]
    }
   ],
   "source": [
    "prompt = relevance_prompt.format(emotion_examples[1].text, emotion_examples[1].llm_label, emotion_examples[1].claims[2])\n",
    "response = query_openai(prompt)\n",
    "print(\"Text:\", emotion_examples[1].text)\n",
    "print(\"Emotion Label:\", emotion_examples[1].llm_label)\n",
    "print(\"Claim:\", emotion_examples[1].claims[2])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "143c99f3-0101-456b-bf20-6f78cbd7e90c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: And they lived happily ever after.\n",
      "Emotion Label: joy\n",
      "Claim: The phrase typically signifies a positive and fulfilling conclusion to a story.\n",
      "Relevance: Yes\n",
      "\n",
      "Reasoning: The claim is relevant because the phrase \"And they lived happily ever after\" is commonly associated with fairy tales and stories that end on a positive, satisfying note. This association supports the emotion label of amusement by indicating a light-hearted and cheerful conclusion, which is often found in amusing and entertaining stories. The claim does not speculate beyond what is expressed in the text, as the phrase itself directly suggests a positive ending, aligning with feelings of amusement.\n"
     ]
    }
   ],
   "source": [
    "prompt = relevance_prompt.format(emotion_examples[2].text, emotion_examples[1].llm_label, emotion_examples[2].claims[1])\n",
    "response = query_openai(prompt)\n",
    "print(\"Text:\", emotion_examples[2].text)\n",
    "print(\"Emotion Label:\", emotion_examples[2].llm_label)\n",
    "print(\"Claim:\", emotion_examples[2].claims[1])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86e93a9-6ecb-4298-8e6f-f1eeecdfbdfa",
   "metadata": {},
   "source": [
    "### Stage 2: Distill relevant claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55d52a4d-327f-4e41-a29c-9277e4b45b95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.27s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.11s/it]\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.08s/it]\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.12s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.27s/it]\n",
      "100%|██████████| 3/3 [00:06<00:00,  2.10s/it]\n",
      "100%|██████████| 3/3 [00:04<00:00,  1.37s/it]\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "relevance_prompt = \"\"\"You will be given a text, its emotion label, and a claim that may or may not be relevant to an explanation of the emotion label. Your task is to decide whether the claim is relevant to explaining the emotion label for this specific text.\n",
    "\n",
    "A claim is relevant if and only if:\n",
    "(1) It is supported by the content of the text (i.e., it does not hallucinate or speculate beyond what is said).\n",
    "(2) It helps explain why the text received the given emotion label (i.e., it directly relates to tone, phrasing, or other aspects relevant to the label).\n",
    "\n",
    "Return your answer as:\n",
    "Relevance: <Yes/No>\n",
    "Reasoning: <A brief explanation of your judgment, pointing to specific support or lack thereof>\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "[Example 1]\n",
    "Text: Creepy Yoda voicepack tbh\n",
    "Emotion Label: disapproval\n",
    "Claim: The use of the word \"creepy\" paired with \"Yoda voicepack\" suggests a playful tone.\n",
    "Relevance: No  \n",
    "Reasoning: The claim is not relevant because it does not contribute to the emotion label of disapproval. \n",
    "\n",
    "[Example 2]\n",
    "Text: Motor Kombat was awesome. Goofy as hell, but awesome.\n",
    "Emotion Label: amusement\n",
    "Claim: There is an entertaining sentiment typically associated with amusement.\n",
    "Relevance: Yes  \n",
    "Reasoning: The claim is relevant because it accurately captures the tone of the text. The description of \"Motor Kombat\" as \"awesome\" and \"goofy as hell\" suggests an enjoyable and entertaining experience, which aligns with the entertaining sentiment associated with amusement. The text's phrasing supports the emotion label of amusement.\n",
    "\n",
    "[Example 3]\n",
    "Text: And they lived happily ever after.\n",
    "Emotion Label: joy\n",
    "Claim: The phrase typically signifies a positive and fulfilling conclusion to a story.\n",
    "Relevance: Yes\n",
    "Reasoning: The claim is relevant because the phrase \"And they lived happily ever after\" is commonly associated with fairy tales and stories that end on a positive, satisfying note. This association supports the emotion label of amusement by indicating a light-hearted and cheerful conclusion, which is often found in amusing and entertaining stories. The claim does not speculate beyond what is expressed in the text, as the phrase itself directly suggests a positive ending, aligning with feelings of amusement.\n",
    "\n",
    "Now, determine whether the following claim is relevant to the given text and emotion label:\n",
    "Text: {}\n",
    "Emotion Label: {}\n",
    "Claim: {}\n",
    "\"\"\"\n",
    "\n",
    "def is_claim_relevant(text: str, rating: str, claim: str):\n",
    "    prompt = relevance_prompt.format(text, rating, claim)\n",
    "    response = query_openai(prompt)\n",
    "    if response == \"ERROR\":\n",
    "        print(\"Error in querying OpenAI API\")\n",
    "        return None\n",
    "    response = response.replace(\"Relevance:\", \"\").strip()\n",
    "    response = response.split(\"\\n\")\n",
    "    relevance = response[0].strip()\n",
    "    reasoning = response[1].replace(\"Reasoning:\", \"\").strip()\n",
    "    return relevance, reasoning\n",
    "\n",
    "\n",
    "def distill_relevant_features(example: EmotionExample):\n",
    "    relevant_claims = []\n",
    "    for claim in tqdm(example.claims):\n",
    "        relevance, reasoning = is_claim_relevant(example.text, example.llm_label, claim)\n",
    "        if relevance is None:\n",
    "            continue\n",
    "        if relevance == \"Yes\":\n",
    "            relevant_claims.append(claim)\n",
    "    return relevant_claims\n",
    "\n",
    "for example in emotion_examples:\n",
    "    relevant_claims = distill_relevant_features(example)\n",
    "    example.relevant_claims = relevant_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "268de10f-360a-457f-9aec-df58f2b0968e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The use of the word \"creepy\" suggests a sentiment of annoyance or discomfort.',\n",
       " 'The phrase \"tbh\" (to be honest) shows dissatisfaction with the Yoda voicepack.',\n",
       " 'The speaker is dissatisfied with the portrayal of the Yoda voicepack.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_examples[0].relevant_claims"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18500f1d-39d7-44e1-ba49-7c42b19733b9",
   "metadata": {},
   "source": [
    "### Stage 3: Calculate alignment scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1280e3d-ee39-4a0f-8eaa-fca9fe409087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:05<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "alignment_prompt = \"\"\"You will be given a text, its emotion label, and a claim that relates to why that label was given. \n",
    "\n",
    "Your task is as follows:\n",
    "1. On a -2 to 2 scale, rate the valence of what is conveyed in the claim. \n",
    "2. On a -2 to 2 scale, rate the arousal of what is conveyed in the claim. \n",
    "\n",
    "Valence is the degree of positivity or negativity expressed in a sentence. It ranges from negative (sadness, displeasure) to positive (happiness, pleasure). -2 = very negative valence and 2 = very positive valence.\n",
    "Arousal is the level of intensity or energy conveyed by the emotion in a sentence. It ranges from low (calm, tired) to high (alarmed, astonished). -2 = very low arousal and 2 = very high arousal.\n",
    "\n",
    "\n",
    "Return your answer as:\n",
    "Valence Rating: <rating>\n",
    "Arousal Rating: <rating>\n",
    "Reasoning: <A brief explanation of why you gave the valence and arousal ratings that you did.>\n",
    "\n",
    "Here are some examples:\n",
    "\n",
    "[Example 1]\n",
    "Text: And they lived happily ever after.\n",
    "Emotion Label: joy\n",
    "Claim: The phrase \"And they lived happily ever after\" conveys a sense of joy.\n",
    "Valence Rating: 2\n",
    "Arousal Rating: -1\n",
    "Reasoning: The claim emphasizes the positive emotional resolution implied by the phrase “And they lived happily ever after,” which is strongly associated with joy and satisfaction. However, while the valence is very high due to the happy sentiment, the arousal is relatively low—it suggests contentment and peace rather than excitement or high energy.\n",
    "\n",
    "[Example 2]\n",
    "Text: Motor Kombat was awesome. Goofy as hell, but awesome.\n",
    "Emotion Label: amusement\n",
    "Claim: There is an entertaining sentiment typically associated with amusement.\n",
    "Valence Rating: 2\n",
    "Arousal Rating: 1.5\n",
    "Reasoning: The claim highlights a strongly positive, fun sentiment (“awesome,” “amusement”) indicating high valence. The enthusiastic tone also suggests a relatively high energy or arousal level.\n",
    "\n",
    "[Example 3]\n",
    "Text: This feels more like r/fellowkids to me. This is nothing compared to some of the more dystopian stuff the government has pushed out to be fair.\n",
    "Emotion Label: disapproval\n",
    "Claim: The feeling of the content being forced or out of touch aligns with a sense of disapproval.\n",
    "Valence Rating: -1\n",
    "Arousal Rating: 0.5\n",
    "Reasoning: The claim highlights a negative evaluation—feeling that something is \"forced or out of touch\"—which supports a moderately negative valence. The arousal is slightly above neutral because the tone implies a level of irritation or critical engagement, but it isn’t highly emotional or intense.\n",
    "\n",
    "Now, determine the valence and arousal ratings for the following claim:\n",
    "Text: {}\n",
    "Emotion Label: {}\n",
    "Claim: {}\n",
    "\"\"\"\n",
    "\n",
    "def calculate_expert_alignment_score(text: str, label: str, claim: str):\n",
    "    prompt = alignment_prompt.format(text, label, claim)\n",
    "    response = query_openai(prompt)\n",
    "    if response == \"ERROR\":\n",
    "        print(\"Error in querying OpenAI API\")\n",
    "        return None\n",
    "    response = [e for e in response.strip().split(\"\\n\") if e != \"\"]\n",
    "    valence_rating = float(response[0].replace(\"Valence Rating:\", \"\").strip())\n",
    "    arousal_rating = float(response[1].replace(\"Arousal Rating:\", \"\").strip())\n",
    "    alignment_score = max(abs(valence_rating), abs(arousal_rating))\n",
    "    reasoning = response[2].replace(\"Reasoning:\", \"\").strip()\n",
    "    return valence_rating, arousal_rating, alignment_score, reasoning\n",
    "\n",
    "for example in emotion_examples:\n",
    "    valence_ratings = []\n",
    "    arousal_ratings = []\n",
    "    alignment_scores = []\n",
    "    reasonings = []\n",
    "    for claim in tqdm(example.relevant_claims):\n",
    "        valence_rating, arousal_rating, alignment_score, reasoning = calculate_expert_alignment_score(example.text, example.llm_label, claim)\n",
    "        # if category is None:\n",
    "        #     continue\n",
    "        valence_ratings.append(valence_rating)\n",
    "        arousal_ratings.append(arousal_rating)\n",
    "        alignment_scores.append(alignment_score)\n",
    "        reasonings.append(reasoning)\n",
    "    example.valence_ratings = valence_ratings\n",
    "    example.arousal_ratings = arousal_ratings\n",
    "    example.alignment_scores = alignment_scores\n",
    "    example.reasonings = reasonings\n",
    "    \n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9d50078-cf85-4773-ae88-a9eb853f49df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5, -1.5, -1.5]\n",
      "[1.0, 0.5, 1.0]\n",
      "[1.5, 1.5, 1.5]\n",
      "['The claim uses the term \"creepy\" to express a negative emotion, signifying a moderately negative valence related to the feeling of annoyance or discomfort. Although it does not convey extreme negativity, it emphasizes displeasure. The arousal rating is higher due to the word \"creepy,\" which indicates a heightened level of awareness or reaction to what is being described but does not suggest extreme energy or intensity.', 'The claim describes a sentiment of dissatisfaction, which is clearly negative, hence the negative valence rating. However, it’s not an extremely intense or deep negativity, so the valence is rated at -1.5 rather than -2. Regarding arousal, the use of \"tbh\" indicates a mild level of energy or engagement, suggesting that the speaker is slightly worked up about it, but not overly upset or excited, leading to a moderately low arousal rating.', 'The claim reflects a negative emotional reaction, given words like \"dissatisfied\" and labeling the voicepack as \"creepy,\" contributing to a quite negative valence. The level of arousal is above neutral because \"annoyance\" and expressions of dissatisfaction typically involve some degree of heightened emotion or agitation, but it is not extremely intense.']\n"
     ]
    }
   ],
   "source": [
    "print(example.valence_ratings)\n",
    "print(example.arousal_ratings)\n",
    "print(example.alignment_scores)\n",
    "print(example.reasonings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "600c8291-268b-4e79-a99c-6cbbd35f0af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.5, 1.5, 1.5]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.alignment_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
